00:00:00.000 --> 00:00:05.360
Hey everyone, my name is Greg Hogg and welcome to my channel. Today we'll be forecasting Microsoft
大家好，我的名字是Greg Hogg，欢迎来到我的频道。今天我们将使用LSTM神经网络对

00:00:05.360 --> 00:00:10.720
stock using LSTM neural networks. This is a very important project to put on your resume, 
微软股票进行预测。这是一个非常重要的项目，可以放在你的简历上，

00:00:10.720 --> 00:00:16.080
so I'd really highly recommend watching the video in its entirety. I made it as clear and concise as 
所以我真的强烈建议你完整地观看这个视频。我尽可能地使其清晰和

00:00:16.080 --> 00:00:20.880
I possibly could, so I really think you're going to find this useful. Enjoy the video, I'll see you in
简洁，所以我真的认为你会发现这很有用。请欣赏视频，我们在里面见。

00:00:20.880 --> 00:00:26.960
there. We first want to grab the dataset which we can get from this Yahoo Finance link here,
我们首先要抓取数据集，我们可以从这个雅虎财经的链接中获得，

00:00:26.960 --> 00:00:31.840
which will bring us to Microsoft Corporation stock page we can scroll down and change the
我们要下载，这将带来一个csv到你的电脑。

00:00:31.840 --> 00:00:37.840
time period from one year to max to get all of the information and then click apply we want to
我们可以向下滚动，将时间段从一年改为最长，以获得所有的信息，然后点击应用。

00:00:37.840 --> 00:00:43.360
download which will bring a csv to your computer we need to bring that csv into our environment


00:00:43.360 --> 00:00:48.960
so in google collab we go here and then upload the file we can simply rename it by deleting
我们需要把这个csv带入我们的环境，所以在Google Collab中，我们去这里，然后上传文件。

00:00:48.960 --> 00:00:56.240
those extra characters and pressing enter so we will do import pandas as pd and make df equal to
我们可以通过删除这些多余的字符并按回车键来简单地重命名。

00:00:57.200 --> 00:01:07.280
dot read csv passing the file name of msft.csv close that and then outputting df 9082 rows
所以我们将做导入pandas作为pd，并使df等于点读csv，传递msft.csv的文件名，关闭它，然后输出df。

00:01:07.280 --> 00:01:14.240
of stock information it goes all the way from the beginning 1986 all the way till now today
9082行股票信息，它从一开始（1986年）一直到现在（今天是2022年3月23日）。

00:01:14.240 --> 00:01:20.080
which is 2022 march 23rd if you're following along you might see a different date here
9082行股票信息，它从一开始（1986年）一直到现在（今天是2022年3月23日）。

00:01:20.080 --> 00:01:26.320
closer to your today notice that we don't trade stocks every single day there's a gap here 19
如果你一直在关注，你可能会在这里看到一个不同的日期，更接近于你的今天。

00:01:26.320 --> 00:01:31.680
and 20 don't exist and many other pieces in the middle don't exist as well that is okay
请注意，我们不是每天都在交易股票，这里有一个缺口（19和20不存在），中间的许多其他作品也不存在。

00:01:31.680 --> 00:01:36.960
looking at the different columns of the data set we have the date and on that date what the
看一下数据集的不同栏目，我们有日期和在该日期的股票开盘价，当天的最高值，当天的最低值，收盘价，调整后的收盘价，然后是当天的股票交易量。

00:01:36.960 --> 00:01:43.760
stock opened at the highest value for that day the lowest value for that day what it closed at
看一下数据集的不同栏目，我们有日期和在该日期的股票开盘价，当天的最高值，当天的最低值，收盘价，调整后的收盘价，然后是当天的股票交易量。

00:01:43.760 --> 00:01:48.800
the adjusted closing value and then the volume of stocks traded that day we're going to keep
看一下数据集的不同栏目，我们有日期和在该日期的股票开盘价，当天的最高值，当天的最低值，收盘价，调整后的收盘价，然后是当天的股票交易量。

00:01:48.800 --> 00:01:54.640
things simple by just using the closing value so we'll have the date and what that value was
我们要保持简单，只使用收盘价值，所以我们将有日期和该日期结束时的价值。

00:01:54.640 --> 00:02:00.640
at the end of that date we're going to discard the other columns we can do that by doing df is equal
我们要保持简单，只使用收盘价值，所以我们将有日期和该日期结束时的价值。

00:02:00.640 --> 00:02:07.120
to df and just the name of those two columns which is date and then close we'll set that
我们可以通过做df等于df，只做这两列的名字，也就是date，然后关闭。

00:02:07.120 --> 00:02:12.480
and then outputting df we should see only those two different columns we currently have a problem
所以df.pop传递了日期，然后输出df，我们会看到它完全做到了我们所期望的，使日期列成为索引，然后我们只是把结束值作为一个列。

00:02:12.480 --> 00:02:17.600
with our date column as it's actually not a date it's just a string that has the year then the
目前，我们的日期列有一个问题，因为它实际上不是一个日期，它只是一个字符串，有年、月、日。

00:02:17.600 --> 00:02:24.960
month then the day we can see this if we type df sub date we should see name of date except it's
目前，我们的日期列有一个问题，因为它实际上不是一个日期，它只是一个字符串，有年、月、日。

00:02:24.960 --> 00:02:31.680
a d type of object we want that to be a date we usually use this thing called date time so we will
我们可以看到，如果我们输入df sub date，我们应该看到'name of date'，只不过它是一个d类型的对象。

00:02:31.680 --> 00:02:40.000
import date time and then make a function so we will define a function called string to date time
所以我们将导入日期时间，然后制作一个函数。

00:02:40.000 --> 00:02:45.440
which is going to take a string s which will be any of these strings here any string that looks
我们还想指定一个新的度量，这将是度量的等值，我们需要把它放在一个列表中，平均绝对误差（MAE）。

00:02:45.440 --> 00:02:50.960
like this we're going to pass that to the function in s and it's going to return the associated date


00:02:50.960 --> 00:02:56.400
time for that string so in this function we'll create a variable called split and set that
我们将把它传递给's'中的函数，它将返回该字符串的相关日期时间。

00:02:56.400 --> 00:03:03.120
equal to the s dot split the hyphen which is the separator for each of these so a split is going to


00:03:03.120 --> 00:03:09.040
be the list of the year and then the month and then the day we can extract those three pieces
因此，"拆分 "将是年的清单，然后是月的清单，然后是日的清单。

00:03:09.040 --> 00:03:18.480
year month and day equal to the split of zero split of one and split of two these objects are


00:03:18.480 --> 00:03:23.920
actually strings right now we want to make them integers so we'll just wrap each of them in int
这些对象现在实际上是字符串，我们想把它们变成整数，所以我们要用'int'把它们每个人包起来。

00:03:26.880 --> 00:03:34.400
so we can just return the datetime.datetime and then pass the year equal to our year
所以我们可以直接返回datetime.datetime，然后把年份传给我们，月份传给我们，日期传给我们。

00:03:34.400 --> 00:03:40.560
the month equal to our month and the day equal to our day we'll now test out our function
所以我们可以直接返回datetime.datetime，然后把年份传给我们，月份传给我们，日期传给我们。

00:03:40.560 --> 00:03:48.000
by creating an object called date time underscore object equal to the string to date time so calling
现在，我们将通过创建一个名为date time underscore object的对象来测试我们的函数，该对象等于日期时间的字符串。

00:03:48.000 --> 00:03:56.720
our function and we'll pass the first day in our data set which happens to be 1986-03-19
因此，调用我们的函数，我们将传递我们的数据集中的第一天，刚好是1986-03-19。

00:03:56.720 --> 00:04:04.240
if we output this date time object we should see that it outputs datetime.datetime of 1986 319 and
如果我们输出这个日期时间对象，我们应该看到它输出的是1986年3月的datetime.datetime，这是针对时间的，但我们现在不需要这些了。

00:04:04.240 --> 00:04:09.600
this is for the time but we don't need any of that now what we need to do is apply this function to
如果我们输出这个日期时间对象，我们应该看到它输出的是1986年3月的datetime.datetime，这是针对时间的，但我们现在不需要这些了。

00:04:09.600 --> 00:04:15.920
everything in our date column because we have in df this whole date column we want to make all of
我们需要做的是将这个函数应用于我们的日期列中的所有内容，因为我们在df中拥有整个日期列，我们想让所有这些日期字符串成为实际的日期对象。

00:04:15.920 --> 00:04:24.640
these date strings actual date objects so we'll set df subdate equal to itself so df subdate dot
我们需要做的是将这个函数应用于我们的日期列中的所有内容，因为我们在df中拥有整个日期列，我们想让所有这些日期字符串成为实际的日期对象。

00:04:24.640 --> 00:04:30.160
apply so we're applying a function to that column just the one that we made above we can pass string


00:04:30.160 --> 00:04:35.280
to date time into this function note that we're not calling the function here we're passing the
我们可以在这个函数中传递字符串到日期时间。

00:04:35.280 --> 00:04:42.160
function itself to the supply function now if we were to output our data frame column again df sub
所以，这意味着我们需要改变上面的窗口化函数，或者说，实际上并没有改变窗口化函数本身，只是改变了我们调用它的方式。

00:04:42.160 --> 00:04:47.440
date should now show us the following it looks like this is an error but this is just a warning
现在，如果我们再次输出我们的数据框架列，df sub date现在应该向我们显示如下。

00:04:47.440 --> 00:04:53.840
this is okay it looks like our column is the same as it was before but actually the d type is now


00:04:53.840 --> 00:05:00.080
date time 64. this is just what pandas converts it to this is actually what we want our data frame


00:05:00.080 --> 00:05:06.000
is almost ready we just have one more step if you look at df you can see that it's index this column
我们的数据框架几乎已经准备好了，我们只剩下一个步骤。

00:05:06.000 --> 00:05:12.880
right here is actually integers we want to replace that column and make that date column the index we
如果你看一下df，你可以看到它的索引这一列在这里实际上是整数。

00:05:12.880 --> 00:05:21.280
can do that very easily by setting df.index equal to the df.pop which means we take away the column
我们可以通过设置df.index等于df.pop来非常容易地做到这一点，这意味着我们拿走了这一列并将其返回。

00:05:21.280 --> 00:05:29.040
and return it so df.pop passing the date and then outputting df we'll see that it did exactly what


00:05:29.040 --> 00:05:34.560
we desired make that date column the index and then we just have the closing value as a column
所以df.pop传递了日期，然后输出df，我们会看到它完全做到了我们所期望的，使日期列成为索引，然后我们只是把结束值作为一个列。

00:05:34.560 --> 00:05:42.400
now that we did that we can quickly plot our data using matplotlib if we do import matpotlib.pyplot
现在我们做到了，我们可以用matplotlib快速绘制我们的数据。

00:05:42.400 --> 00:05:52.960
as plt we can do a plt.plot of the df.index and the df sub close what we can see is from 1986
如果我们把matpotlib.pyplot导入为plt，我们就可以对df.index和df.sub close进行plt.绘图。

00:05:52.960 --> 00:06:00.320
all the way up until 2022 the stock goes absolutely crazy after it hits about 2016 or so
我们可以看到的是，从1986年一直到2022年，股票在进入2016年左右后绝对是疯狂的，然后在最后有一点下降。

00:06:00.320 --> 00:06:05.520
and then there's a little bit of a drop at the end now because we're using the lstm model we need to
我们可以看到的是，从1986年一直到2022年，股票在进入2016年左右后绝对是疯狂的，然后在最后有一点下降。

00:06:05.520 --> 00:06:11.040
convert this into a supervised learning problem we're going to do this by making a new function
现在，由于我们使用的是lstm模型，我们需要将其转换为一个监督学习问题。

00:06:11.040 --> 00:06:18.720
we'll call it define df to windowed df it's going to take the data frame which will just pass df
我们把它称为定义df到窗口化df。

00:06:18.720 --> 00:06:25.760
it'll take a first date string and a last date string and then a positive integer we'll set
它将接受一个第一个日期字符串和最后一个日期字符串，然后是一个正整数，我们将默认设置它等于3。

00:06:25.760 --> 00:06:31.040
it equal to 3 by default this function is also going to need numpy so we're going to
它将接受一个第一个日期字符串和最后一个日期字符串，然后是一个正整数，我们将默认设置它等于3。

00:06:31.040 --> 00:06:37.280
import numpy as np now it turns out that this code is extremely difficult to write
这个函数也将需要numpy，所以我们要把numpy导入为np。

00:06:37.280 --> 00:06:42.560
so i'm going to just go in here and paste in the code if you need to know what that code is


00:06:42.560 --> 00:06:46.960
make sure you go to the video description and check out the tutorial and look at it there


00:06:46.960 --> 00:06:52.480
i also pasted in how to create this object called window df which is calling this function with


00:06:52.480 --> 00:06:58.480
certain parameters i'll explain that very shortly i just need to show you the result of window df


00:06:58.480 --> 00:07:05.280
window df is now a data frame where we have a target date column a target minus 3 minus 2 minus


00:07:05.280 --> 00:07:11.360
1 and then the target these are all the stock closing values from before so this target date


00:07:11.360 --> 00:07:20.400
corresponds to that value here if we look above at 3 18 it should be 0.099 so 0 3 18 let's take it


00:07:20.400 --> 00:07:29.040
one more time for me to remember oh 3 18 is 0.099 why don't we have this row that row and that row


00:07:29.040 --> 00:07:35.920
well that is all about what this windowed function is so this window data frame is converting a date


00:07:35.920 --> 00:07:43.840
into getting its three previous values and then what it actually was so if we go back again 0.097


00:07:44.400 --> 00:07:50.960
if we look at what .097 is that is three days before this is the target date


00:07:50.960 --> 00:07:56.400
this is three days before if we were to look at target minus two this would be target minus two


00:07:56.400 --> 00:08:03.200
for that date and this is target minus 1 and this is the target we have that for every single date


00:08:03.200 --> 00:08:09.760
that it allows for so of course we couldn't have dates previous than this because we didn't have a


00:08:09.760 --> 00:08:15.200
whole three values before it this was the first date that we could start with hence we actually


00:08:15.200 --> 00:08:21.520
called that as the starting date there as the last date that's the last one we wanted which is


00:08:21.520 --> 00:08:27.120
right here the three previous and then its target value right there the reason i started calling


00:08:27.120 --> 00:08:31.920
it target is to think about this column as the output because that's what our machine learning


00:08:31.920 --> 00:08:38.880
model needs we have what led up to it so three days before two days before one day before what


00:08:38.880 --> 00:08:45.040
is our corresponding output because this is the input that's fed into the model and this is the


00:08:45.040 --> 00:08:50.800
corresponding output it's just like a regression problem or any other supervised learning problem


00:08:50.800 --> 00:08:57.280
you have an input and then you have an output you have another input you have another output this


00:08:57.280 --> 00:09:03.280
is just the whole data frame which displays the inputs the outputs and the corresponding date for


00:09:03.280 --> 00:09:08.720
that output so that was really how we converted this problem to a supervised learning problem


00:09:08.720 --> 00:09:14.960
we set up its output date with that output and its corresponding input for that row now we just


00:09:14.960 --> 00:09:20.640
need to convert this into numpy arrays so that we can feed it directly into a tensorflow model so
现在，由于我们使用的是lstm模型，我们需要将其转换为一个监督学习问题。

00:09:20.640 --> 00:09:27.040
to do that we're going to create a function we're going to call it windowed df so it takes a window


00:09:27.040 --> 00:09:34.800
df like above and converts it to date x y okay so this is actually three things we're going to get a


00:09:34.800 --> 00:09:40.720
list of dates we're going to get an input matrix x actually it's going to be a three-dimensional


00:09:40.720 --> 00:09:48.080
tensor we'll see shortly and y is going to be the output vector so x is going to be this matrix here


00:09:48.080 --> 00:09:53.600
except it's actually going to be three-dimensional y is going to be this output vector here and dates


00:09:53.600 --> 00:09:58.400
we want to keep those so dates is going to be this column here this function is just going to


00:09:58.400 --> 00:10:05.920
take one parameter called window data frame first is going to do df as numpy it's going to convert


00:10:05.920 --> 00:10:14.480
the whole data frame into a numpy array we do that with windowed data frame dot 2 underscore numpy


00:10:14.480 --> 00:10:21.920
bracket bracket to get the dates it's very easy we just set dates equal to df underscore as numpy


00:10:21.920 --> 00:10:27.040
and then we need to get all of the rows so we put a colon and then we put 0 to say just the first


00:10:27.040 --> 00:10:32.720
column because it's this column right here getting the input matrix is a little bit more confusing so
但我们只想从第一列开始，因为我们不想要那个日期列。

00:10:32.720 --> 00:10:40.400
we're going to call it first middle matrix not our final input matrix middle matrix is equal to df
所以，我们要做的是，得到日期x和y。

00:10:40.400 --> 00:10:46.000
underscore as numpy and again we want all the rows so we'll put a colon but we only want to start at


00:10:46.000 --> 00:10:51.600
the first column because we don't want that date column and then we want to go up until but not
但我们只想从第一列开始，因为我们不想要那个日期列。

00:10:51.600 --> 00:10:58.400
include the last one so 1 until negative 1 says all of these rows here that's what the colon does


00:10:58.400 --> 00:11:05.360
and then 1 to negative 1 says just this piece of information in the middle so all of this piece now


00:11:05.360 --> 00:11:09.760
unfortunately what you'll find if you go through like that is that it's actually the wrong shape


00:11:09.760 --> 00:11:16.320
for the lstm we need x is equal to middle matrix but then we need to do a reshape so we'll do a


00:11:16.320 --> 00:11:23.040
reshape where the first dimension is the length of dates so this is the number of observations
因此，我们将做一个重塑，第一个维度是日期的长度。

00:11:23.040 --> 00:11:28.080
that's pretty common for any tensorflow model but now we need the second piece of this shape to be
这对任何tensorflow模型来说都很常见。

00:11:28.080 --> 00:11:34.080
middle matrix dot shape sub 1. that's just however many columns we had and it would be


00:11:34.080 --> 00:11:38.960
the same as that n our window value i'm just making it this because we have access to that
它和之前的大图完全一样，只是我加入了递归日期和递归预测，并把它也放在图例中。

00:11:38.960 --> 00:11:45.280
the last piece just has to be a 1 here because we are technically only using one variable we have
最后一块只是在这里必须是1，因为技术上我们只使用一个变量。

00:11:45.280 --> 00:11:50.560
three different values of that variable and how it changes over time but we're still only doing
我们有该变量的三个不同的值，以及它是如何随时间变化的，但我们仍然只是在做我们所谓的单变量预测，因为我们只是在看收盘值是如何随时间变化的。

00:11:50.560 --> 00:11:56.000
what we call univariate forecasting because we're just looking at how the closing value changes over
我们有该变量的三个不同的值，以及它是如何随时间变化的，但我们仍然只是在做我们所谓的单变量预测，因为我们只是在看收盘值是如何随时间变化的。

00:11:56.000 --> 00:12:02.480
time if instead we had used some of those values at the very beginning like the open the high the


00:12:02.480 --> 00:12:07.440
volume and those variables well then we'd have to put a different number down here we'd have to


00:12:07.440 --> 00:12:12.480
put two or three or four as this number we're just doing one because we're doing univariate


00:12:12.480 --> 00:12:18.000
forecasting now luckily from here this function is very easy we can just get our output vector


00:12:18.000 --> 00:12:25.200
y is equal to df as numpy where again we want all of the rows but we only want the last column


00:12:25.200 --> 00:12:32.160
that we can just do return three things dates x and y there's just a minor difficulty if you go
我们可以只做返回日期，X，Y。

00:12:32.160 --> 00:12:39.840
on later you'll see that has an error that we can fix with dot as type float 32 actually np


00:12:39.840 --> 00:12:47.840
dot float32 if we change those for x and you also do that for y y dot as type numpy.float32


00:12:47.840 --> 00:12:52.560
you'll fix a weird error you'll find later now to call this function we again want those three
你会看到有一个错误，我们可以用.astype(np.float32)实际上是np.float32，如果我们为x改变这些，你也为y这样做，y.astype(np.float32)，你会修复一个奇怪的错误，你以后会发现。

00:12:52.560 --> 00:13:02.000
things we'll get dates x and y and set that equal to windowed df to date x y just our function there


00:13:02.000 --> 00:13:07.600
and we'll pass in our window df from before these three things should be numpy arrays so we will get
我们将传入之前的window_df。

00:13:07.600 --> 00:13:15.120
dates.shape x dot shape and y dot shape and see that we have 9079 of each of these three things


00:13:15.120 --> 00:13:21.040
our input matrix and then three by one because we're looking three steps in the past but for only
这三样东西应该是numpy数组，所以我们会得到dates.shape、x.shape和y.shape，看到这三样东西各有9079个，我们的输入矩阵，然后是3x1，因为我们要看三步，但只针对一种类型的变量。

00:13:21.040 --> 00:13:27.440
one type of variable now we're going to split the data into train validation and testing partitions
这三样东西应该是numpy数组，所以我们会得到dates.shape、x.shape和y.shape，看到这三样东西各有9079个，我们的输入矩阵，然后是3x1，因为我们要看三步，但只针对一种类型的变量。

00:13:27.440 --> 00:13:33.120
the training will train the model the validation will help train the model and then the testing
训练将训练模型，验证将帮助训练模型，然后测试是我们要用来真正评估模型的性能。

00:13:33.120 --> 00:13:38.480
is what we're going to use to really evaluate the performance of the model we need two integers to
训练将训练模型，验证将帮助训练模型，然后测试是我们要用来真正评估模型的性能。

00:13:38.480 --> 00:13:44.960
help with the split we'll get q80 first that's going to be the integer of the length of dates
我们需要两个整数来帮助进行分割。

00:13:44.960 --> 00:13:51.920
times 0.8 then we'll get q90 which is equal to the int of the length of dates times 0.9


00:13:52.560 --> 00:13:59.040
so we'll make the training partition the first 80 percent so we'll get dates train x train and
因此，我们将把培训分区作为前80%。

00:13:59.040 --> 00:14:04.240
y train each of those are going to be each of their pieces so this will be dates but then


00:14:04.240 --> 00:14:12.240
only up until q80 to make it the first 80 percent we'll do the same thing with x so x up until q80
因此，这将是日期，但然后只到q80，使其成为前80％。

00:14:12.240 --> 00:14:18.080
and then y up until q80 because it's a little bit slow i'm just going to paste in these two lines
我们将对x做同样的事情，所以x一直到q80，然后y一直到q80。

00:14:18.080 --> 00:14:26.000
to get vowel and test which we can get val dates val x file and y about by going dates q 80 to q 90


00:14:26.000 --> 00:14:33.280
then x q a to q 90 and y q to q82 q90 that's all that information between the 80 and 90


00:14:33.280 --> 00:14:40.240
pieces then we just get the testing information by saying q90 onward to get that last 10 so you can


00:14:40.240 --> 00:14:46.400
see it's ordered the first training piece is up until the first eighty percent the validation is
所以你可以看到它是有顺序的：第一块训练是到前百分之八十，验证是百分之八十到九十（10%），然后测试是九十以后的最后百分之十。

00:14:46.400 --> 00:14:52.480
the eighty to ninety percent ten percent and then the test is that final ten percent from the ninety
所以你可以看到它是有顺序的：第一块训练是到前百分之八十，验证是百分之八十到九十（10%），然后测试是九十以后的最后百分之十。

00:14:52.480 --> 00:14:58.800
onward we can visualize and color this very well with matplotlib so we'll do plt.plot then we're


00:14:58.800 --> 00:15:06.880
going to get dates train and then y train we'll do the same so plt.plot for val so dates underscore
然后我们要去买枣子车，再去买Y车。

00:15:06.880 --> 00:15:15.200
val and y val finally the same for test plt.plot dates test and y test and we'll just add in a


00:15:15.200 --> 00:15:20.880
legend so that you can see which is which although it should be pretty obvious plt.legend train then


00:15:20.880 --> 00:15:26.720
validation then test if you plot that you're going to see that train is all this information here


00:15:26.720 --> 00:15:32.160
marked by the blue then validation is this piece and then test is this piece here it's time to
如果你绘制这个图，你会看到火车是这里所有的信息，由蓝色标记，然后验证是这一块，然后测试是这里这一块。

00:15:32.160 --> 00:15:38.240
create and train our model we can do a few imports from tensorflow from tensorflow.comstep models
现在是创建和训练我们的模型的时候了。

00:15:38.240 --> 00:15:43.760
get sequential we're going to build a sequential model from tensorflow.curious.optimizers


00:15:43.760 --> 00:15:49.760
we'll get atom that's the optimizer we're going to use and then from tensorflow.kira's import layers


00:15:49.760 --> 00:15:55.440
we'll make a model that is sequential and built up of many layers so we'll define our model and we're
我们将制作一个有顺序的、由许多层组成的模型。

00:15:55.440 --> 00:16:01.440
going to call it model is equal to a sequential and then we'll pass that a list of layers so the
所以我们将定义我们的模型，我们将称它为模型等于顺序，然后我们将传递给它一个层的列表。

00:16:01.440 --> 00:16:07.360
first one is just the input layers dot input and we need to specify the shape of the input
所以第一个只是输入层.点.输入，我们需要指定输入的形状。

00:16:07.360 --> 00:16:14.400
remember we don't need to specify the batch number or how many examples three by one again it's three


00:16:14.400 --> 00:16:20.080
because we're doing three days in the past and that's one because we need only one feature only
三乘以一，又是三，因为我们在做过去三天的工作，那是一，因为我们只需要一个功能，只需要单变量预测。

00:16:20.080 --> 00:16:26.080
univariate forecasting now that we've specified the input layer we're ready to do an lstm layer so
三乘以一，又是三，因为我们在做过去三天的工作，那是一，因为我们只需要一个功能，只需要单变量预测。

00:16:26.080 --> 00:16:32.560
we will do layers dot lstm and capitals and this number is relatively arbitrary but we will choose
因此，我们将做layer.dot.lstm和capitals，而这个数字是相对随意的。

00:16:32.560 --> 00:16:40.080
64 which is a relatively big but not super big number of neurons for the lstm all that you really


00:16:40.080 --> 00:16:45.280
need to know about this number is the bigger the number the more complicated the model is
关于这个数字，你真正需要知道的是，这个数字越大，模型就越复杂，越容易过度拟合，而且被认为是越重的。

00:16:45.280 --> 00:16:51.040
the more prone it is to overfitting and the more heavy duty it is considered we will add instead
关于这个数字，你真正需要知道的是，这个数字越大，模型就越复杂，越容易过度拟合，而且被认为是越重的。

00:16:51.040 --> 00:16:58.560
of an lstm a dense layer layers.dense will choose 32 for a similar reason as above you're also very


00:16:58.560 --> 00:17:03.600
welcome to stack dense layers and so we'll just actually paste that in again and have another
我们也非常欢迎你把密集层堆积起来，所以我们就把这个再贴上，再来个32。

00:17:03.600 --> 00:17:09.360
32. we're not going to mess with the activation functions for the lstm but for the dents it's


00:17:09.360 --> 00:17:15.840
usually a good idea to set activation equal to relu so we will do that for both of those dense
我们不打算弄乱LSTM的激活函数，但对于密集层，通常是一个好主意，设置激活等于relu，所以我们将为这两个密集层做这个。

00:17:15.840 --> 00:17:22.080
layers now we must specify the output of our model and since we are only forecasting one variable


00:17:22.080 --> 00:17:29.600
we're just trying to predict say the next value we only want this to be a layers dot dense of one
现在我们必须指定我们模型的输出，由于我们只预测一个变量（我们只是想预测说下一个值），我们只希望这是一的层.密，在这里我们不改变激活函数，因为默认情况下它是线性的，这是所希望的。

00:17:29.600 --> 00:17:35.520
where we don't change the activation function as by default it's linear which is desired we can now
现在我们必须指定我们模型的输出，由于我们只预测一个变量（我们只是想预测说下一个值），我们只希望这是一的层.密，在这里我们不改变激活函数，因为默认情况下它是线性的，这是所希望的。

00:17:35.520 --> 00:17:42.080
close this up and specify that the model is going to be compiled to compile the model we must set
我们现在可以关闭这个，并指定模型要被编译。

00:17:42.080 --> 00:17:47.040
the loss function and the loss function we want to minimize is the mean squared error so we will
为了编译模型，我们必须设置损失函数，而我们想要最小化的损失函数是平均平方误差（MSE），所以我们只需写出平均平方误差的字符串mse。

00:17:47.040 --> 00:17:52.320
just write the string of mse for mean squared error we also need to specify the optimizer
为了编译模型，我们必须设置损失函数，而我们想要最小化的损失函数是平均平方误差（MSE），所以我们只需写出平均平方误差的字符串mse。

00:17:52.320 --> 00:17:58.960
so we will set the optimizer equal to the atom optimizer where we specify that the learning rate
我们还需要指定优化器，所以我们将设置优化器等于亚当优化器，其中我们指定学习率等于0.001。

00:17:58.960 --> 00:18:05.600
is equal to for this example it turns out that 0.001 is going to work out pretty well if you're


00:18:05.600 --> 00:18:10.000
doing a different problem the learning rate is something you definitely want to play around with
事实证明，在这个例子中，0.001的效果很好，但如果你在做一个不同的问题，学习率是你肯定要玩的东西，还有这里的这些值。

00:18:10.000 --> 00:18:17.200
as well as these values here we also want to specify a new metric is going to be metrics equals
事实证明，在这个例子中，0.001的效果很好，但如果你在做一个不同的问题，学习率是你肯定要玩的东西，还有这里的这些值。

00:18:17.200 --> 00:18:23.920
we need to put it in a list it's the mean absolute error this number tells us on average how much
我们还想指定一个新的度量，这将是度量的等值，我们需要把它放在一个列表中，平均绝对误差（MAE）。

00:18:23.920 --> 00:18:29.600
we're off by rather than the squared distance we'd rather look at this although we need to minimize


00:18:29.600 --> 00:18:35.520
the mse as this is not differentiable we're now ready to fit the model so we can do model dot
我们宁愿看这个，虽然我们需要最小化MSE，因为这不是可分的。

00:18:35.520 --> 00:18:42.320
fit we pass our inputs of x train and y train and then we specify that the validation data


00:18:42.320 --> 00:18:48.880
is equal to the tuple of x val and y val we're going to let this run for 100 epochs
我们传递x_train和y_train的输入，然后我们指定验证数据等于x_val和y_val的元组。

00:18:48.880 --> 00:18:55.840
which means 100 runs through the data set i'm going to press enter and we can see what happens
我们要让它运行100个epochs，也就是在数据集上运行100次。

00:19:01.520 --> 00:19:05.680
as we can see at this point it looks like it's not really changed very much
我们可以看到，在这一点上，它看起来并没有真正改变多少，所以我们实际上可以取消这个，它将保存到目前为止的任何进展。

00:19:05.680 --> 00:19:10.800
so we can actually cancel this and it is going to save whatever progress it's done so far now
我们可以看到，在这一点上，它看起来并没有真正改变多少，所以我们实际上可以取消这个，它将保存到目前为止的任何进展。

00:19:10.800 --> 00:19:16.640
to briefly analyze this we mostly care about the validation mean absolute error going down
现在，简单分析一下，我们主要关心的是验证的平均绝对误差会下降。

00:19:16.640 --> 00:19:23.120
we can see it's at 14 at the beginning then it goes to 11 10 9 and then it hovers around 8 9
我们可以看到它一开始是14，然后是11、10、9。

00:19:23.120 --> 00:19:27.840
10 and that's when i was ready to stop it because it wasn't really changing all that much


00:19:27.840 --> 00:19:33.120
it's much easier to visualize what's going on instead with graphs so before worrying about the
用图表来直观地了解情况要容易得多，所以在担心代码之前，我只想给你看看我们可以为它在训练集上预测的漂亮图片。

00:19:33.120 --> 00:19:38.800
code i'm just going to show you the pretty picture we can make for it predicting on the training set


00:19:38.800 --> 00:19:47.040
so the orange is the actual observed observations it's what really happened from 1986 to 2016. the
因此，橙色是实际观察到的数据；这是从1986年到2016年真实发生的情况。

00:19:47.040 --> 00:19:52.960
blue is what we predicted so each time it got the three previous and it tried to predict the next
蓝色是我们预测的。

00:19:52.960 --> 00:19:58.880
one that's also what it was trained on to make that run we simply get the training predictions


00:19:58.880 --> 00:20:05.520
with model.predict on x train and then we have to do a flatten then we can do a plot of dates train
为了使其运行，我们只需在x_train上用model.predict获得训练预测，然后我们必须做一个flatten。

00:20:05.520 --> 00:20:10.800
and the train predictions and dates train and y train that's that blue and the orange curve


00:20:10.800 --> 00:20:15.600
and then we just create the legend since i explained that code for the train i feel no real
这就是那个蓝色和橙色的曲线，然后我们就创建图例。

00:20:15.600 --> 00:20:21.040
need to explain it much for the validation as this is literally the same thing but replacing the word
既然我解释了火车的代码，我觉得没有必要对验证进行过多的解释，因为这实际上是同样的事情，只是把 "火车 "这个词换成了 "val"。

00:20:21.040 --> 00:20:28.400
train with val so for the validation we get this graph or it follows it until you know about 2017


00:20:28.400 --> 00:20:33.360
and then it just really flattens off which is the same time when it actually starts to pick
或者说，它一直跟着它，直到你知道2017年，然后它就真的变平了，这也是它真正开始回升的时间。

00:20:33.360 --> 00:20:39.600
up so the observations what really happened is it went up like this but the predictions it actually


00:20:39.600 --> 00:20:44.560
just started to zone off and it couldn't follow it anymore if we were to look at the test this
因此，观察结果，真正发生的是它像这样上升，但预测，它实际上只是开始分区，它不能再跟随它。

00:20:44.560 --> 00:20:51.440
is again just replacing that word train with test this picture is even worse it doesn't follow it at
如果我们看一下测试，这又只是把 "训练 "这个词替换成 "测试"。

00:20:51.440 --> 00:20:56.400
all it actually thinks it's going down a little bit whereas it's going up a lot and then it goes


00:20:56.400 --> 00:21:01.440
down i'm now going to put all three of those pictures on the same graph again the code is


00:21:01.440 --> 00:21:07.120
not hard it's just annoying where we first plot the training predictions and the observations


00:21:07.120 --> 00:21:12.320
the validation predictions and the observations same for the test and then we create the legend
我们会再次看到，我们的平均绝对误差下降得很低，对于验证来说，比以前好了很多。

00:21:12.320 --> 00:21:17.760
we see that this picture again for the training it follows it very closely and for the red piece
我们看到这张图，同样是训练，它非常紧跟它。

00:21:17.760 --> 00:21:23.280
is what actually happened in validation the green is what it thought happened not good at all the
而对于红色这块，是在验证中实际发生的。

00:21:23.280 --> 00:21:28.320
brown is what really happened and the purple is what it thought for the test really really bad
棕色的是真实发生的情况，紫色的是它认为的测试情况。

00:21:28.320 --> 00:21:35.040
at that point it turns out that these lstm models are very bad at what we call extrapolating and so


00:21:35.040 --> 00:21:41.280
if it was trained on data only in this range here only up until like the 50 value it's not going to
事实证明，这些LSTM模型非常不擅长我们所说的外推，因此，如果它只在这个范围内的数据上进行训练，只到像50的数值，它就不擅长预测这么高的东西，即使它被给予，比如说，他的输入，这里的这三个数值，也不知道该怎么处理，因为它不会很好地进行外推。

00:21:41.280 --> 00:21:47.760
be good at predicting stuff this high even though it is given say his input these three values here
事实证明，这些LSTM模型非常不擅长我们所说的外推，因此，如果它只在这个范围内的数据上进行训练，只到像50的数值，它就不擅长预测这么高的东西，即使它被给予，比如说，他的输入，这里的这三个数值，也不知道该怎么处理，因为它不会很好地进行外推。

00:21:47.760 --> 00:21:53.760
and has no idea what to do with them because it's not going to extrapolate well extrapolate means
事实证明，这些LSTM模型非常不擅长我们所说的外推，因此，如果它只在这个范围内的数据上进行训练，只到像50的数值，它就不擅长预测这么高的东西，即使它被给予，比如说，他的输入，这里的这三个数值，也不知道该怎么处理，因为它不会很好地进行外推。

00:21:53.760 --> 00:22:00.160
basically learn data outside its range a line extrapolates well because if we drew a line here
外推的意思是基本上在其范围之外学习数据。

00:22:00.160 --> 00:22:05.840
we could just continue drawing that line up like that but if the lstm is only trained on this data
一条线可以很好地推断，因为如果我们在这里画了一条线，我们就可以像这样继续往上画这条线。

00:22:05.840 --> 00:22:11.600
here it will have no idea what to do when the values are increasing and are this big another


00:22:11.600 --> 00:22:17.440
way to think about it is that all this information here it might actually not be that helpful because
另一种思考方式是，所有这些信息在这里，实际上可能没有那么大的帮助，因为在这里，价值像这样一路上升，模式开始变化很大。

00:22:17.440 --> 00:22:23.280
over here the values are way up like this and the pattern starts changing a lot so maybe we don't
另一种思考方式是，所有这些信息在这里，实际上可能没有那么大的帮助，因为在这里，价值像这样一路上升，模式开始变化很大。

00:22:23.280 --> 00:22:28.240
want to train it on all of this maybe we just want to train it on say this information here
也许我们只是想训练它，比如说这里的信息，然后在这里进行验证。

00:22:28.240 --> 00:22:34.000
and then validate over here so we'll do just that we're going to pick some day over here to start
也许我们只是想训练它，比如说这里的信息，然后在这里进行验证。

00:22:34.000 --> 00:22:39.680
training at we do need to know that this date is actually in the data set and for that we'll go to


00:22:39.680 --> 00:22:46.000
our data set over here and select the time period of one year and if we apply that we just need to
我们确实需要知道这个日期确实在数据集中，为此我们将进入我们的数据集，选择一年的时间段。

00:22:46.000 --> 00:22:53.280
scroll back all the way to the bottom and see that one date that we know exists is march 25th 2021
如果我们应用这一点，我们只需要一直向后滚动到底部，看到我们知道存在的一个日期是2021年3月25日。

00:22:53.280 --> 00:22:59.040
we will use that as our starting value instead so that means we need to change our windowed function
我们将使用这个值作为我们的起始值。

00:22:59.040 --> 00:23:03.680
above or not actually change the windowed function itself but just change how we're


00:23:03.680 --> 00:23:11.600
calling it we need to change this value here to be the year is going to be 2021 03 is fine and


00:23:11.600 --> 00:23:17.600
then 2 5 is a date we know exists as you can see here i had this in a comment for me to remember
我们需要改变这里的值，使之成为2021年，03年就可以了，然后2 5是一个我们知道存在的日期，你可以在这里看到。

00:23:17.600 --> 00:23:24.960
so now the first date will be 2021 0325 and these are its corresponding information the end date


00:23:24.960 --> 00:23:31.600
is exactly the same and we only have 252 rows this time way less information we should have no
结束日期完全相同，而这次我们只有252行，信息量少了很多。

00:23:31.600 --> 00:23:37.280
problem just re-running the cells we already did so we're going to do that which gets dates x and y
我们只需重新运行我们已经做过的细胞就应该没有问题了。

00:23:37.280 --> 00:23:42.480
note that they're smaller this time we'll again split the data set and make sure that we plot
请注意，这一次它们更小了。

00:23:42.480 --> 00:23:48.320
it properly so our starting date up until about the middle over here is train then validation


00:23:48.320 --> 00:23:54.000
then test and note that we've already seen values in this range so it should be okay to predict


00:23:54.000 --> 00:23:59.360
values in the same range over here since we only change the number of things the model is seeing
请注意，我们已经看到了这个范围内的数值，所以在这里预测相同范围内的数值应该是没有问题的，因为我们只是改变了模型看到的东西的数量。

00:23:59.360 --> 00:24:04.640
the model is actually fine as is we can run that again and it's going to run a lot faster
该模型实际上很好，因为它是。

00:24:04.640 --> 00:24:10.640
now we'll see again that our mean absolute error goes down pretty low and for the validation a lot


00:24:10.640 --> 00:24:15.440
better than it was before we can recreate all of our graphs so to plot the training
我们会再次看到，我们的平均绝对误差下降得很低，对于验证来说，比以前好了很多。

00:24:15.440 --> 00:24:21.440
we can see here the train it doesn't follow it quite as well as before but that's totally okay
因此，为了绘制训练图，我们可以看到这里的火车它并不像以前那样跟随它，但这完全没有问题。

00:24:21.440 --> 00:24:27.040
if we see here for the validation it got so much better now look at how zoomed in this is
如果我们看到这里的验证，它就会变得好得多。

00:24:27.040 --> 00:24:32.320
these values are extremely close to each other and if we were to do it for the test as well the tests
这些数值极其接近，如果我们对测试也这样做，测试结果也是极其接近的。

00:24:32.320 --> 00:24:38.000
are also extremely close to each other if we were to plot them all on the same graph again we would
这些数值极其接近，如果我们对测试也这样做，测试结果也是极其接近的。

00:24:38.000 --> 00:24:44.880
see here zoomed out that they're all very close to each other the predicted first the observation is
如果我们再把它们绘制在同一张图上，我们会看到这里放大后，它们都非常接近。

00:24:44.880 --> 00:24:50.800
very very close no matter whether it's the train the validation or the test now the video could be


00:24:50.800 --> 00:24:57.200
done here but i want to show you how you could try and predict long term because all of these values


00:24:57.200 --> 00:25:03.360
any of these predictions we're assuming we had the actual three days before and that data was real
现在视频可以在这里完成，但我想告诉你，你可以尝试长期预测，因为所有这些价值，任何这些预测我们都假设我们有前三天的实际情况，而且这些数据是真实的，然后我们用前三天的数据来进行预测，然后第二天我们会有实际的三。

00:25:03.360 --> 00:25:09.040
then we used those three days before to make the prediction and then the next day we would have the
现在视频可以在这里完成，但我想告诉你，你可以尝试长期预测，因为所有这些价值，任何这些预测我们都假设我们有前三天的实际情况，而且这些数据是真实的，然后我们用前三天的数据来进行预测，然后第二天我们会有实际的三。

00:25:09.040 --> 00:25:13.840
actual three and then we'd use that predict the next day well what we're actually going to do


00:25:13.840 --> 00:25:19.760
is train here and then pretend that's all the data that we have and let the model recursively
好吧，我们实际上要做的是在这里进行训练，然后假装这是我们拥有的所有数据，让模型递归地预测未来，看看它有什么要说的。

00:25:19.760 --> 00:25:25.680
predict the future and see what it has to say so to make that function we're first going to do from
好吧，我们实际上要做的是在这里进行训练，然后假装这是我们拥有的所有数据，让模型递归地预测未来，看看它有什么要说的。

00:25:25.680 --> 00:25:32.880
copy import deep copy we'll make a list and start to build this up called recursive predictions
因此，为了实现这个功能，我们首先要做的是，从copy导入deepcopy。

00:25:32.880 --> 00:25:38.240
is equal to an empty list and then we'll get recursive dates these are the dates on which
我们会做一个列表，并开始建立这个叫做递归_预测等于空的列表。

00:25:38.240 --> 00:25:45.040
we're predicting for this is already known and this is equal to np dot concatenate the dates val
好了，现在我们需要转到前面两个实际看到的信息，然后是下一个预测值，因为我们需要开始使用我们预测的值。

00:25:45.040 --> 00:25:51.600
and the test val this is because the dates we're predicting are here onward so we're training on


00:25:51.600 --> 00:25:55.920
all of this in fact we've already trained on all of that and then the recursive predictions


00:25:55.920 --> 00:26:01.200
are going to be for these following dates so now we can loop through those dates for target
事实上，我们已经对所有这些进行了训练，然后递归_预测将是对以下这些日期的预测。

00:26:01.200 --> 00:26:07.920
date in the recursive dates we'll get our most recent input so the last we'll call it window i'm


00:26:07.920 --> 00:26:14.640
just copying it so we don't change anything deep copy of x train sub negative one because the last
我只是复制它，所以我们不改变任何东西，deepcopy(x_train[-1])，因为我们真正能访问的最后一个窗口是这里的最后三个，它被存储在x_train[-1]中。

00:26:14.640 --> 00:26:21.360
window that we actually had access to was the very last three over here that is stored in x trains of
我只是复制它，所以我们不改变任何东西，deepcopy(x_train[-1])，因为我们真正能访问的最后一个窗口是这里的最后三个，它被存储在x_train[-1]中。

00:26:21.360 --> 00:26:26.560
negative one and we need to start predicting for the future so we need to get our next prediction


00:26:26.560 --> 00:26:32.320
so the prediction for the next day that will be equal to model.predict unfortunately we actually


00:26:32.320 --> 00:26:39.520
have to make it the numpy.array of the list of the last window but really it's just the last window
不幸的是，我们实际上必须让它成为最后一个窗口的列表的numpy.array，但实际上它只是最后一个窗口。

00:26:39.520 --> 00:26:44.560
don't worry too much about that piece that and then flatten it like before then what we can do
不要太担心这一块。

00:26:44.560 --> 00:26:52.800
is recursive predictions dot append so add that to our list with next prediction then we need to


00:26:52.800 --> 00:26:58.000
update this last window because we just made a prediction for the next day well now we need to
然后，我们需要更新这最后一个窗口，因为我们刚刚对第二天进行了预测。

00:26:58.000 --> 00:27:04.160
move on to the previous two informations that were actually seen and then the next predicted
好了，现在我们需要转到前面两个实际看到的信息，然后是下一个预测值，因为我们需要开始使用我们预测的值。

00:27:04.160 --> 00:27:09.280
value because we need to start using the values that we're predicting that's why it's called


00:27:09.280 --> 00:27:16.960
recursive predicting so we'll actually set last window sub negative one equal to next prediction
这一块就在这里，是递归的预测。

00:27:17.760 --> 00:27:23.040
sorry i have an error here this should actually be dates test and then if we run that i'm now


00:27:23.040 --> 00:27:27.920
going to paste in again some annoying code but it'll look very familiar it's exactly the same
然后如果我们运行这个，我现在要再次粘贴一些恼人的代码，但它看起来会非常熟悉。

00:27:27.920 --> 00:27:34.000
as that big graph as before except i added in the recursive dates and the recursive predictions
它和之前的大图完全一样，只是我加入了递归日期和递归预测，并把它也放在图例中。

00:27:34.000 --> 00:27:39.600
and that put that in the legend as well if i were to plot this you will see something very funny
它和之前的大图完全一样，只是我加入了递归日期和递归预测，并把它也放在图例中。

00:27:39.600 --> 00:27:46.080
this piece right here is the recursive predictions the model has absolutely no idea on how to predict
这一块就在这里，是递归的预测。

00:27:46.080 --> 00:27:52.160
in the future it just thinks it'll be what it was before and actually that's a reasonable prediction


00:27:52.160 --> 00:27:58.240
predicting stocks is incredibly difficult there is of course the trend we can analyze we saw before
预测股票是非常困难的。

00:27:58.240 --> 00:28:03.040
that the graph really started to go up and that would indicate to you that it's a good stock to
我们之前看到，该图真的开始上升，这将向你表明，这是一个值得购买的好股票。

00:28:03.040 --> 00:28:08.080
buy but that doesn't mean i can guarantee that and i don't want to be liable for you predicting


00:28:08.080 --> 00:28:14.080
any sort of stocks with any sort of model and by no means is the model we made useless it's just
但这并不意味着我可以保证，我不想为你用任何一种模式预测任何一种股票而承担责任。

00:28:14.080 --> 00:28:20.080
on the micro scale of per day should i sell or buy of course in general people generally think
只是在每天的微观尺度上，我应该卖出还是买入。

00:28:20.080 --> 00:28:25.840
of stocks for the long term what should i do to make money in the long term but on a micro scale
当然，一般来说，人们普遍认为股票是长期的，我应该怎么做才能长期赚钱。

00:28:25.840 --> 00:28:30.720
it's important to know as well so i hope you enjoyed that video if it brought you value please
但从微观上看，知道这一点也很重要。

00:28:30.720 --> 00:28:35.440
drop a like and consider subscribing it really really helps and i'll see you next time guys 
如果它给你带来了价值，请留下一个赞并考虑订阅。

