{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DIR = os.path.abspath(\"..\\\\..\\\\\")\n",
    "DATA_DIR = DIR + \"\\\\input\\\\qmdata0819\"\n",
    "\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_all_csv = open(DATA_DIR + \"\\\\all.csv\", \"r\" , encoding=\"utf8\")\n",
    "\n",
    "data_ = []\n",
    "for line in read_all_csv:\n",
    "    line = line.strip()\n",
    "    time_, item_ = line.split(',')\n",
    "    data_.append([time_, item_])\n",
    "\n",
    "# 第一行是表格的标题栏，pop掉\n",
    "data_.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为 data_ 增加第三维内容。\n",
    "第三维内容是时间戳，来自每条记录的时间文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for each in data_:\n",
    "    each.append(int(time.mktime(time.strptime(each[0], \"%Y-%m-%d %H:%M:%S\"))))\n",
    "\n",
    "len(data_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据时间戳，分析数据的段落。前后2条数据的时间戳间隔不为58的，都视为段落分割点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = []\n",
    "all_segs = []\n",
    "for i in range(len(data_)):\n",
    "    segment.append(data_[i])\n",
    "    if i<len(data_)-1 and i > 0 and data_[i+1][2] - data_[i][2] != 58:\n",
    "        all_segs.append(segment)\n",
    "        segment = []\n",
    "\n",
    "all_segs.append(segment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于每一个段落，读取它的第0 - 20条数据，作为新的数据段落的起点。把它对应的第21条数据作为相应的结果。依次逐条推进，形成新的数据集段落列表 all_rows。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ = []\n",
    "all_rows = []\n",
    "for each in all_segs:\n",
    "    for i in range(20,len(each)-1):\n",
    "        list_ = each[i-20:i]\n",
    "        row_ = [list_, each[i]]\n",
    "        all_rows.append(row_)\n",
    "\n",
    "len(all_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为 all_rows 里的每一条数据，增加一项统计数据，计算这一条数据里的20条历史记录，各物品对应的统计量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_names = [\"钢琴\", \"小提琴\", \"吉他\", \"贝斯\", \"架子鼓\", \"竖琴\", \"萨克斯风\", \"圆号\"]\n",
    "def count_items(a_list:list):\n",
    "    items = []\n",
    "    # each 是每个回合的数据\n",
    "    # each[1]是名字\n",
    "    for each in a_list:\n",
    "        items.append(each[1])\n",
    "    \n",
    "    count_result = []\n",
    "    for n in item_names:\n",
    "        count_result.append(items.count(n))\n",
    "    \n",
    "    # count_result是每一行数据的20个回合里，每个物品数量的统计\n",
    "    return count_result\n",
    "\n",
    "# each 是20个回合的出货数据 + 第21回合的出货数据\n",
    "# each[0] 是20回合的结果\n",
    "history = []\n",
    "for each in all_rows:\n",
    "    history.append(count_items(each[0]))\n",
    "\n",
    "len(history)\n",
    "history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = []\n",
    "for i in range(len(history)):\n",
    "    merge_data.append([all_rows[i][0], all_rows[i][1], history[i]])\n",
    "\n",
    "merge_data[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建数据集\n",
    "merge_data 里的 each ，each[0]里的每个 item，抽取 item[1]，即物品的名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "items_name_20 = []\n",
    "item_result = ''\n",
    "count = []\n",
    "data_for_pd = []\n",
    "for each in merge_data:\n",
    "    item_result = each[1][1]\n",
    "    count = each[2]\n",
    "    if item_result in item_names[:4]:\n",
    "        if count[item_names.index(item_result)] > np.mean(count[:4]):\n",
    "            result = '高'\n",
    "        elif count[item_names.index(item_result)] < np.mean(count[:4]):\n",
    "            result = '低'\n",
    "        else:\n",
    "            result = '平'\n",
    "    elif item_result in item_names[-4:]:\n",
    "        if count[item_names.index(item_result)] > np.mean(count[-4:]):\n",
    "            result = '高'\n",
    "        elif count[item_names.index(item_result)] < np.mean(count[-4:]):\n",
    "            result = '低'\n",
    "        else:\n",
    "            result = '平'\n",
    "    for item in each[0]:\n",
    "        items_name_20.append(item[1])\n",
    "    high_low = []\n",
    "    for item in items_name_20:\n",
    "        if item in item_names[:4]:\n",
    "            if count[item_names.index(item)] > np.mean(count[:4]):\n",
    "                high_low.append('高')\n",
    "            elif count[item_names.index(item)] < np.mean(count[:4]):\n",
    "                high_low.append('低')\n",
    "            else:\n",
    "                high_low.append('平')\n",
    "        elif item in item_names[-4:]:\n",
    "            if count[item_names.index(item)] > np.mean(count[-4:]):\n",
    "                high_low.append('高')\n",
    "            elif count[item_names.index(item)] < np.mean(count[-4:]):\n",
    "                high_low.append('低')\n",
    "            else:\n",
    "                high_low.append('平')\n",
    "    data_for_pd.append([items_name_20,high_low, count, item_result, result])\n",
    "    items_name_20 = []\n",
    "\n",
    "\n",
    "data_for_pd[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_1_4 = []\n",
    "for each in data_for_pd:\n",
    "    a_1_4.append(each[1]+[each[4]])\n",
    "\n",
    "a_1_4[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_1_4 = pd.DataFrame(a_1_4,columns=['col_1','col_2','col_3','col_4','col_5','col_6','col_7','col_8','col_9','col_10','col_11','col_12','col_13','col_14','col_15','col_16','col_17','col_18','col_19','col_20','result',])\n",
    "\n",
    "pd_1_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_1_4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd_1_4['result']\n",
    "\n",
    "X = pd_1_4.drop(['result'], axis=1)\n",
    "\n",
    "print(f'X: {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')\n",
    "print(f'y_train: {y_train.shape}')\n",
    "print(f'y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林树的数量\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=80, num=10)]\n",
    "# 每个分割集上的最大特征数\n",
    "max_featues = ['auto', 'sqrt']\n",
    "# 最大树层级数\n",
    "max_depth = [2,4]\n",
    "# 最小样本数\n",
    "min_samples_split = [2,5]\n",
    "min_samples_leaf = [1,2]\n",
    "bootstrap = [True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_featues,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'bootstrap': bootstrap\n",
    "}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_Model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_Grid = GridSearchCV(estimator=rf_Model, param_grid=param_grid, cv=10, verbose=2, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_Grid.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
