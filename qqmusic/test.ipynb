{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = [1,18,9,11]\n",
    "counter.sort(reverse=0)\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试字典排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "console = Console()\n",
    "temp_dict = {\n",
    "    '预测-预测': 0,\n",
    "    '补充-补充': 0,\n",
    "    '预测-补充': 0,\n",
    "    '补充-预测': 0,   \n",
    "    '预测-忽略': 0,    \n",
    "    '补充-忽略': 0,\n",
    "    '忽略-预测': 0,\n",
    "    '忽略-补充': 0,\n",
    "}\n",
    "temp_list = ['补充','预测','忽略','补充','忽略','预测','忽略','补充','补充','补充','补充','预测','补充','忽略','补充','预测','忽略','预测','补充','忽略']\n",
    "console.print(len(temp_list))\n",
    "for k in range(len(temp_list)-1):\n",
    "    print(temp_list[k]+ '-' + temp_list[k+1])\n",
    "    if temp_list[k] == temp_list[k+1] and temp_list[k] != '忽略' and temp_list[k+1] != '忽略':\n",
    "        if temp_list[k] == '预测':\n",
    "            temp_dict['预测-预测'] = temp_dict['预测-预测'] + 1\n",
    "        if temp_list[k] == '补充':\n",
    "            temp_dict['补充-补充'] = temp_dict['补充-补充'] + 1\n",
    "    if temp_list[k] != temp_list[k+1]:\n",
    "        if temp_list[k] == '预测' and temp_list[k+1] == '补充':\n",
    "            temp_dict['预测-补充'] = temp_dict['预测-补充'] + 1\n",
    "        if temp_list[k] == '预测' and temp_list[k+1] == '忽略':\n",
    "            temp_dict['预测-忽略'] = temp_dict['预测-忽略'] + 1            \n",
    "        if temp_list[k] == '补充' and temp_list[k+1] == '预测':\n",
    "            temp_dict['补充-预测'] = temp_dict['补充-预测'] + 1\n",
    "        if temp_list[k] == '补充' and temp_list[k+1] == '忽略':\n",
    "            temp_dict['补充-忽略'] = temp_dict['补充-忽略'] + 1\n",
    "        if temp_list[k] == '忽略' and temp_list[k+1] == '预测':\n",
    "            temp_dict['忽略-预测'] = temp_dict['忽略-预测'] + 1\n",
    "        if temp_list[k] == '忽略' and temp_list[k+1] == '补充':\n",
    "            temp_dict['忽略-补充'] = temp_dict['忽略-补充'] + 1\n",
    "\n",
    "msg_list = ''\n",
    "for each in temp_dict:\n",
    "    msg_list = msg_list + each\n",
    "    msg_list = msg_list + \":\" + str(temp_dict[each]) + \" | \"\n",
    "\n",
    "console.print(msg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "微信消息推送测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Python源码资料电子书领取群 279199867\n",
    "\n",
    "def send_wechat(msg_title,msg):\n",
    "    token = 'f848a62a0c7541fd8519247fd3f139f9' #前边复制到那个token\n",
    "    title = msg_title\n",
    "    content = msg\n",
    "    template = 'html'\n",
    "    topic = '1022111101'\n",
    "    url = f\"http://www.pushplus.plus/send?token={token}&title={title}&content={content}&template={template}&topic={topic}\"\n",
    "    print(url)\n",
    "    r = requests.get(url=url)\n",
    "    print(r.text)\n",
    "\n",
    "def send_wechat_self(msg):\n",
    "    token = 'f848a62a0c7541fd8519247fd3f139f9'#前边复制到那个token\n",
    "    title = 'Music Kingdom'\n",
    "    content = msg\n",
    "    template = 'html'\n",
    "    url = f\"https://www.pushplus.plus/send?token={token}&title={title}&content={content}&template={template}\"\n",
    "    print(url)\n",
    "    r = requests.get(url=url)\n",
    "    print(r.text)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    msg = '用这个消息推送试试监控王国的运行。'\n",
    "    # send_wechat('音乐王国',msg)\n",
    "    send_wechat_self(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试计算\n",
    "print(int(60*60/58))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = 'buy%spiano%s&%s'\n",
    "\n",
    "content = content + 'voilin'\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取当前日期的代码\n",
    "import time\n",
    "y = time.strftime(\"%Y-%m-%d\", time.localtime(time.time()))\n",
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试openai的API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = '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'\n",
    "items = ['钢琴','小提琴','吉他','贝斯','架子鼓','竖琴','萨克斯风','圆号']\n",
    "\n",
    "csv_path = r'D:\\OneDrive\\0_caijia\\1_code\\python\\yammi_utils\\yammi_utils\\qqmusic\\auto2-2022-12-18.csv'\n",
    "read_csv = open(csv_path,'r',encoding='utf8')\n",
    "dataset = []\n",
    "for line in read_csv:\n",
    "    line = line.strip()\n",
    "    if '钢琴' in line:\n",
    "        line = line.replace('钢琴', 'P')\n",
    "    if '小提琴' in line:\n",
    "        line = line.replace('小提琴', 'V')\n",
    "    if '吉他' in line:\n",
    "        line = line.replace('吉他', 'G')\n",
    "    if '贝斯' in line:\n",
    "        line = line.replace('贝斯', 'B')\n",
    "    for item in items[-4:]:\n",
    "        if item in line:\n",
    "            line = line.replace(item, 'H')\n",
    "    dataset.append(line)\n",
    "\n",
    "# print(dataset)\n",
    "\n",
    "# 循环预测30次，每次使用31条数据\n",
    "for i in range(86,87):\n",
    "    text = ''\n",
    "    for j in range(31):\n",
    "        text = text + dataset[j+i] + '；'\n",
    "        k = i+31\n",
    "    \n",
    "    text = '有一段格式为“时间-值”的时间序列值如下：' + text + '已知该序列中的值每次都是基于计算机随机数产生，并且每种值在较长时间线上出现的平均概率都接近20%，如何基于tensorflow的keras构建一个预测模型？用Python代码如何展示你的计算过程'\n",
    "    response = openai.Completion.create(model=\"text-davinci-003\", prompt=text, temperature=0.9, max_tokens=3000)\n",
    "    x = json.dumps(response['choices'])\n",
    "    y = json.loads(x)\n",
    "    print(y[0][\"text\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测模型构建\n",
    "使用Keras构建一个时间序列预测模型，具体思路如下：\n",
    "\n",
    "1. 首先，获取时间序列的输入数据，并将时间序列的值映射到可作为神经网络输入的数量；\n",
    "\n",
    "2. 然后，建立深度神经网络模型，其结构如下：输入层-隐藏层-输出层；\n",
    "\n",
    "3. 最后，使用Adam优化器训练模型，并设置输出节点的激活函数为Softmax，以输出值得概率。\n",
    "\n",
    "### Python代码实现\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 定义输入数据\n",
    "data = [[2022-12-19 01:02:10,G],\n",
    "        [2022-12-19 01:03:08,G], \n",
    "        [2022-12-19 01:04:06,H],\n",
    "        [2022-12-19 01:05:04,P],\n",
    "        [2022-12-19 01:06:02,V],\n",
    "        [2022-12-19 01:07:00,B],\n",
    "        [2022-12-19 01:07:58,V],\n",
    "        [2022-12-19 01:08:56,P],\n",
    "        [2022-12-19 01:09:54,P],\n",
    "        [2022-12-19 01:10:52,G],\n",
    "        [2022-12-19 01:11:50,B],\n",
    "        [2022-12-19 01:12:48,B],\n",
    "        [2022-12-19 01:13:46,G],\n",
    "        [2022-12-19 01:14:44,B],\n",
    "        [2022-12-19 01:15:42,G],\n",
    "        [2022-12-19 01:16:40,G],\n",
    "        [2022-12-19 01:17:38,H],\n",
    "        [2022-12-19 01:18:36,G],\n",
    "        [2022-12-19 01:19:34,B],\n",
    "        [2022-12-19 01:20:32,H],\n",
    "        [2022-12-19 01:21:30,P],\n",
    "        [2022-12-19 01:22:28,G],\n",
    "        [2022-12-19 01:23:26,G],\n",
    "        [2022-12-19 01:24:24,G],\n",
    "        [2022-12-19 01:25:22,G],\n",
    "        [2022-12-19 01:26:20,H],\n",
    "        [2022-12-19 01:27:18,V],\n",
    "        [2022-12-19 01:28:16,V],\n",
    "        [2022-12-19 01:29:14,V],\n",
    "        [2022-12-19 01:30:12,G],\n",
    "        [2022-12-19 01:31:10,B]]\n",
    "\n",
    "# 将时间序列值映射到可作为神经网络的输入\n",
    "# G：0，H：1，P：2，V：3，B：4\n",
    "mappedData=[]\n",
    "for value in data:\n",
    "    if value[1] == 'G':\n",
    "        mappedData.append([value[0], 0])\n",
    "    elif value[1] == 'H':\n",
    "        mappedData.append([value[0], 1])\n",
    "    elif value[1] == 'P':\n",
    "        mappedData.append([value[0], 2])\n",
    "    elif value[1] == 'V':\n",
    "        mappedData.append([value[0], 3])\n",
    "    else:\n",
    "        mappedData.append([value[0], 4])\n",
    "\n",
    "# 构建深度神经网络模型\n",
    "model = Sequential()\n",
    "\n",
    "# 输入层\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(len(mappedData[0]),)))\n",
    "\n",
    "# 隐藏层\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "\n",
    "# 输出层\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(mappedData, epochs=1000, batch_size=32)\n",
    "\n",
    "# 预测\n",
    "predictions = model.predict(mappedData)\n",
    "\n",
    "# 输出预测结果\n",
    "for i in range(len(predictions)):\n",
    "    print(predictions[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python代码如下：\n",
    "```\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 获取序列数据\n",
    "time_list, value_list = [], []\n",
    "data_string = \"\"\"2022-12-19 01:02:10,G；2022-12-19 01:03:08,G；2022-12-19 01:04:06,H；2022-12-19 01:05:04,P；2022-12-19 01:06:02,V；2022-12-19 01:07:00,B；2022-12-19 01:07:58,V；2022-12-19 01:08:56,P；2022-12-19 01:09:54,P；2022-12-19 01:10:52,G；2022-12-19 01:11:50,B；2022-12-19 01:12:48,B；2022-12-19 01:13:46,G；2022-12-19 01:14:44,B；2022-12-19 01:15:42,G；2022-12-19 01:16:40,G；2022-12-19 01:17:38,H；2022-12-19 01:18:36,G；2022-12-19 01:19:34,B；2022-12-19 01:20:32,H；2022-12-19 01:21:30,P；2022-12-19 01:22:28,G；2022-12-19 01:23:26,G；2022-12-19 01:24:24,G；2022-12-19 01:25:22,G；2022-12-19 01:26:20,H；2022-12-19 01:27:18,V；2022-12-19 01:28:16,V；2022-12-19 01:29:14,V；2022-12-19 01:30:12,G；2022-12-19 01:31:10,B；\"\"\"\n",
    "for e in data_string.split(';'):\n",
    "    if not e:\n",
    "        continue\n",
    "    time, value = e.split(',')\n",
    "    time_list.append(time)\n",
    "    value_list.append(value)\n",
    "\n",
    "# 将序列值转换为one_hot编码\n",
    "value_dict = {'G':0, 'H':1, 'V':2, 'P':3, 'B':4}\n",
    "value_one_hot = []\n",
    "for value in value_list:\n",
    "    one_hot = [0] * len(value_dict)\n",
    "    one_hot[value_dict[value]] = 1\n",
    "    value_one_hot.append(one_hot)\n",
    "\n",
    "# 构建模型\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(32, input_shape=(3, ), activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "X = np.array(time_list).reshape(-1, 3)\n",
    "Y = np.array(value_one_hot)\n",
    "model.fit(X, Y, batch_size=4, epochs=50)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据实例\n",
    "data =[\n",
    "    ['2022-12-19 01:02:10','G'],['2022-12-19 01:03:08','G'],\n",
    "    ['2022-12-19 01:04:06','H'],['2022-12-19 01:05:04','P'],\n",
    "    ['2022-12-19 01:06:02','V'],['2022-12-19 01:07:00','B'],\n",
    "    ['2022-12-19 01:07:58','V'],['2022-12-19 01:08:56','P'],\n",
    "    ['2022-12-19 01:09:54','P'],['2022-12-19 01:10:52','G'],\n",
    "    ['2022-12-19 01:11:50','B'],['2022-12-19 01:12:48','B'],\n",
    "    ['2022-12-19 01:13:46','G'],['2022-12-19 01:14:44','B'],\n",
    "    ['2022-12-19 01:15:42','G'],['2022-12-19 01:16:40','G'],\n",
    "    ['2022-12-19 01:17:38','H'],['2022-12-19 01:18:36','G'],\n",
    "    ['2022-12-19 01:19:34','B'],['2022-12-19 01:20:32','H'],\n",
    "    ['2022-12-19 01:21:30','P'],['2022-12-19 01:22:28','G'],\n",
    "    ['2022-12-19 01:23:26','G'],['2022-12-19 01:24:24','G'],\n",
    "    ['2022-12-19 01:25:22','G'],['2022-12-19 01:26:20','H'],\n",
    "    ['2022-12-19 01:27:18','V'],['2022-12-19 01:28:16','V'],\n",
    "    ['2022-12-19 01:29:14','V'],['2022-12-19 01:30:12','G'],\n",
    "    ['2022-12-19 01:31:10','B']]\n",
    "\n",
    "# 导入tensorflow、numpy和keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# 将数据转换成可供序列学习算法使用的格式\n",
    "data = np.array(data)\n",
    "X_train = data[:-1,0]\n",
    "y_train = data[1:,1]\n",
    "\n",
    "# 创建并训练LSTM模型\n",
    "model = Sequential()\n",
    "model.add(LSTM(25, input_dim=1))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "# 预测下一个时间点各个值的置信度\n",
    "next_time = np.array(['2022-12-19 01:32:08'])\n",
    "predictions = model.predict(next_time)\n",
    "print(\"The predictions for the next time point are:\\n G: {0:.2f}, \\n H: {1:.2f}, \\n P: {2:.2f}, \\n V: {3:.2f}, \\n B: {4:.2f}\".format(predictions[0][0], predictions[0][1], predictions[0][2], predictions[0][3], predictions[0][4]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测值：？\n",
    "\n",
    "答：下一个时间点概率最大的值依次为：G、H、P、V、B。\n",
    "\n",
    "Python代码如下：\n",
    "\n",
    "```python\n",
    "#计算每种值出现的概率\n",
    "dict_data = {\"G\": 0, \"H\": 0, \"P\": 0, \"V\": 0, \"B\": 0}\n",
    "elements = [\"G\", \"H\", \"P\", \"V\", \"B\"]\n",
    "for element in elements:\n",
    "    for data in series_data:\n",
    "        if element == data[-1]:\n",
    "            dict_data[element] += 1\n",
    "total = 0\n",
    "for value in dict_data.values():\n",
    "    total += value\n",
    "for key, value in dict_data.items():\n",
    "    dict_data[key] = round(value/total,3)\n",
    "print(\"每种值出现的概率分别为：\", dict_data)\n",
    "\n",
    "#确定下一个时间点概率最大的值\n",
    "max_value = 0\n",
    "max_key = \"\"\n",
    "for key, value in dict_data.items():\n",
    "    if value > max_value:\n",
    "        max_value = value\n",
    "        max_key = key\n",
    "dict_data[max_key] = 0\n",
    "print(\"下一个时间点概率最大的值为：\",max_key)\n",
    "\n",
    "#确定下一个时间点概率最大的值依次为\n",
    "while len(dict_data) > 0:\n",
    "    max_value = 0\n",
    "    max_key = \"\"\n",
    "    for key, value in dict_data.items():\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "            max_key = key\n",
    "    print(\"下一个时间点概率最大的值依次为：\", max_key)\n",
    "    dict_data[max_key] = 0\n",
    "```\n",
    "实际值：2022-12-19 01:32:08,H\n",
    "******************************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测值：\n",
    "\n",
    "由于每种值的出现概率都接近20%，可以考虑使用伪随机数生成器来模拟计算机随机数产生，其中种子值可以调整来控制随机数的输出。\n",
    "\n",
    "Python代码如下：\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "# 设置种子值\n",
    "random.seed(1)\n",
    "\n",
    "# 计算每个时间点的值\n",
    "values = []\n",
    "for i in range(30):\n",
    "    values.append(random.choice(['G', 'H', 'P', 'V', 'B']))\n",
    "\n",
    "# 打印出来\n",
    "print(values)\n",
    "```\n",
    "\n",
    "输出结果为：\n",
    "\n",
    "['G', 'G', 'H', 'P', 'V', 'B', 'V', 'P', 'P', 'G', 'B', 'B', 'G', 'B', 'G', 'G', 'H', 'G', 'B', 'H', 'P', 'G', 'G', 'G', 'G', 'H', 'V', 'V', 'V', 'G', 'B']\n",
    "\n",
    "可以看到，设置种子值为1的情况下，结果与上述的时间序列值一致，可以推断出计算机随机数的种子值为1。\n",
    "\n",
    "下一个时间点概率最大的值依次为G、H、P、V、B。\n",
    "实际值：2022-12-19 01:32:08,H\n",
    "******************************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测值：。\n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "# 初始化随机数种子\n",
    "seed = random.randint(0, 2**32-1)\n",
    "\n",
    "# 随机数种子\n",
    "random.seed(seed)\n",
    "\n",
    "# 计算每个值的概率\n",
    "prob_dict = {'G': 0, 'H': 0, 'P': 0, 'V': 0, 'B': 0}\n",
    "\n",
    "# 时间序列\n",
    "time_series = '2022-12-19 01:02:10,G;2022-12-19 01:03:08,G;2022-12-19 01:04:06,H;2022-12-19 01:05:04,P;2022-12-19 01:06:02,V;2022-12-19 01:07:00,B;2022-12-19 01:07:58,V;2022-12-19 01:08:56,P;2022-12-19 01:09:54,P;2022-12-19 01:10:52,G;2022-12-19 01:11:50,B;2022-12-19 01:12:48,B;2022-12-19 01:13:46,G;2022-12-19 01:14:44,B;2022-12-19 01:15:42,G;2022-12-19 01:16:40,G;2022-12-19 01:17:38,H;2022-12-19 01:18:36,G;2022-12-19 01:19:34,B;2022-12-19 01:20:32,H;2022-12-19 01:21:30,P;2022-12-19 01:22:28,G;2022-12-19 01:23:26,G;2022-12-19 01:24:24,G;2022-12-19 01:25:22,G;2022-12-19 01:26:20,H;2022-12-19 01:27:18,V;2022-12-19 01:28:16,V;2022-12-19 01:29:14,V;2022-12-19 01:30:12,G;2022-12-19 01:31:10,B'\n",
    "\n",
    "# 将时间序列拆分成列表\n",
    "time_list = time_series.split(';')\n",
    "\n",
    "# 计算每个值的概率\n",
    "for time_str in time_list:\n",
    "    time, value = time_str.split(',')\n",
    "    prob_dict[value] += 1\n",
    "\n",
    "# 打印每个值的概率\n",
    "for value, prob in prob_dict.items():\n",
    "    print('{}的概率为：{}'.format(value, prob/len(time_list)))\n",
    "\n",
    "# 计算下一个时间点各个值出现的概率\n",
    "next_prob_dict = {'G': 0, 'H': 0, 'P': 0, 'V': 0, 'B': 0}\n",
    "\n",
    "# 计算下一个时间点的值\n",
    "next_value = random.choices(list(prob_dict.keys()), list(prob_dict.values()))[0]\n",
    "\n",
    "# 更新概率\n",
    "next_prob_dict[next_value] += 1\n",
    "\n",
    "# 打印下一个时间点各个值出现的概率\n",
    "for value, prob in next_prob_dict.items():\n",
    "    print('{}的概率为：{}'.format(value, prob/len(time_list)))\n",
    "```\n",
    "实际值：2022-12-19 01:32:08,H\n",
    "******************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "openai.api_key = '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'\n",
    "\n",
    "text = 'tensorflow和keras是什么关系'\n",
    "response = openai.Completion.create(model=\"text-davinci-003\", prompt=text, temperature=0.9, max_tokens=1024)\n",
    "x = json.dumps(response['choices'])\n",
    "y = json.loads(x)\n",
    "print(y[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络预测测试\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "items = ['钢琴','小提琴','吉他','贝斯','架子鼓','竖琴','萨克斯风','圆号']\n",
    "\n",
    "# 定义输入数据\n",
    "csv_path = r'D:\\OneDrive\\0_caijia\\1_code\\python\\yammi_utils\\yammi_utils\\qqmusic\\auto2-2022-12-18.csv'\n",
    "read_csv = open(csv_path,'r',encoding='utf8')\n",
    "data = []\n",
    "for line in read_csv:\n",
    "    line = line.strip()\n",
    "    if '钢琴' in line:\n",
    "        line = line.replace('钢琴', 'P')\n",
    "    if '小提琴' in line:\n",
    "        line = line.replace('小提琴', 'V')\n",
    "    if '吉他' in line:\n",
    "        line = line.replace('吉他', 'G')\n",
    "    if '贝斯' in line:\n",
    "        line = line.replace('贝斯', 'B')\n",
    "    for item in items[-4:]:\n",
    "        if item in line:\n",
    "            line = line.replace(item, 'H')\n",
    "    time_, value_ = line.split(',')\n",
    "    data.append(value_)\n",
    "\n",
    "# 将时间序列值映射到可作为神经网络的输入\n",
    "# G：0，H：1，P：2，V：3，B：4\n",
    "mappedData=[]\n",
    "formatted_data = []\n",
    "for i in range(len(data)-21):\n",
    "    for j in range(21):\n",
    "        if data[i+j] == 'P':\n",
    "            formatted_data.append(0)\n",
    "        elif data[i+j] == 'V':\n",
    "            formatted_data.append(1)\n",
    "        elif data[i+j] == 'G':\n",
    "            formatted_data.append(2)\n",
    "        elif data[i+j] == 'B':\n",
    "            formatted_data.append(3)\n",
    "        else:\n",
    "            formatted_data.append(4)\n",
    "    mappedData.append(formatted_data)\n",
    "    formatted_data = []\n",
    "\n",
    "train_samples = []\n",
    "train_labels = []\n",
    "for each in mappedData:\n",
    "    train_samples.append(each[:20])\n",
    "    train_labels.append(each[-1])\n",
    "\n",
    "# print(f'训练样本：{train_samples[:5]}')\n",
    "# print(f'训练标签：{train_labels[:5]}')\n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels = np.array(train_labels)\n",
    "# train_labels, train_samples = shuffle(train_labels, train_samples)\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,20))\n",
    "\n",
    "\n",
    "# predict_data = []\n",
    "# for i in range(20):\n",
    "#     if data[-20+i] == 'P':\n",
    "#         predict_data.append(0)\n",
    "#     elif data[-20+i] == 'V':\n",
    "#         predict_data.append(1)\n",
    "#     elif data[-20+i] == 'G':\n",
    "#         predict_data.append(2)\n",
    "#     elif data[-20+i] == 'B':\n",
    "#         predict_data.append(3)\n",
    "#     else:\n",
    "#         predict_data.append(4)\n",
    "\n",
    "# predict_data = np.array([predict_data])\n",
    "# print(predict_data)\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# scaled_predict_data = scaler.fit_transform(predict_data.reshape(-1,20))\n",
    "# print(scaled_predict_data)\n",
    "\n",
    "# 构建深度神经网络模型\n",
    "model = Sequential()\n",
    "\n",
    "# 输入层\n",
    "model.add(Dense(units=20, activation='relu', input_shape=(20,)))\n",
    "\n",
    "# 隐藏层\n",
    "model.add(Dense(units=20, activation='relu'))\n",
    "\n",
    "# 输出层\n",
    "model.add(Dense(units=1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 训练模型\n",
    "model.fit(x = scaled_train_samples, y = train_labels, validation_split=0.2, epochs=300, batch_size=100)\n",
    "\n",
    "# # 预测\n",
    "# predictions = model.predict(predict_data)\n",
    "\n",
    "# # 输出预测结果\n",
    "# for i in range(len(predictions)):\n",
    "#     print(predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "header = ['time']\n",
    "for i in range(20):\n",
    "    header.append('col_'+str(i+1))\n",
    "header.append('result')\n",
    "\n",
    "t = [0,3,-1,-3,3,1,-4,0,3,0,1,0,-2,2,-3,-1,4,-3,2,-1,-2]\n",
    "print(len(t))\n",
    "x = [['2022-12-21 12:00:00'] + t[:-1] + [0]]\n",
    "\n",
    "t = pd.DataFrame(x, columns=header)\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# 测试函数对变量修改的结果\n",
    "\n",
    "def test(list:list):\n",
    "    for i in range(len(list)):\n",
    "        list[i] = i\n",
    "\n",
    "k = ['a','b','c','d','e']\n",
    "\n",
    "test(k)\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "b = 0.1\n",
    "c = 2\n",
    "d = int(a/round((b**c),3))\n",
    "\n",
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
